

---------------------------------------------------------------------------------------------
训练部分，python


  sparse_index = tf.placeholder(tf.int64, [None, 2])
  sparse_ids = tf.placeholder(tf.int64, [None])
  sparse_values = tf.placeholder(tf.float32, [None])
  sparse_shape = tf.placeholder(tf.int64, [2])
  inference_ids = tf.SparseTensor(sparse_index, sparse_ids, sparse_shape)
  inference_values = tf.SparseTensor(sparse_index, sparse_values, sparse_shape)
  inference_logits = inference(inference_ids, inference_values, False)
  inference_softmax = tf.nn.softmax(inference_logits)
  inference_op = tf.argmax(inference_softmax, 1)
  keys_placeholder = tf.placeholder(tf.int32, shape=[None, 1])
  keys = tf.identity(keys_placeholder)




	model_signature = signature_def_utils.build_signature_def(
          inputs={
              "keys": utils.build_tensor_info(keys_placeholder),
              "indexs": utils.build_tensor_info(sparse_index),
              "ids": utils.build_tensor_info(sparse_ids),
              "values": utils.build_tensor_info(sparse_values),
              "shape": utils.build_tensor_info(sparse_shape)
          },
          outputs={
              "keys": utils.build_tensor_info(keys),
              "softmax": utils.build_tensor_info(inference_softmax),
              "prediction": utils.build_tensor_info(inference_op)
          },
          method_name=signature_constants.PREDICT_METHOD_NAME)

      try:
        builder = saved_model_builder.SavedModelBuilder(export_path)
        builder.add_meta_graph_and_variables(
            sess,
            [tag_constants.SERVING],
            clear_devices=True,
            signature_def_map={
                signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
                model_signature,
            },
            #legacy_init_op=legacy_init_op)
            legacy_init_op=tf.group(tf.initialize_all_tables(),
                                    name="legacy_init_op"))

        builder.save()
      except Exception as e:
        logging.error("Fail to export saved model, exception: {}".format(e))



---------------------------------------------------------------------------------------------
预测部分，c++

  //'''
  //Example data:
  //  5:1 6:1 17:1 
  //  5:1 7:1 17:1 
  //  input_index=[0, 5, 0, 6, 0, 17, 1, 5, 1, 7, 1, 17]
  //  input_value=[1, 1, 1, 1, 1, 1]
  //'''

void ServingClient::sparse_matrix_to_tfrequest(unsigned int sample_size, 
                                                unsigned int feature_size,
                                                vector <int> const  & input_index, 
                                                vector <float> const  & input_value, 
                                                PredictRequest & predictRequest) {
    google::protobuf::Map< std::string, tensorflow::TensorProto >& inputs = *predictRequest.mutable_inputs();
    int64_t iBegin = TNOWMS;
    int64_t iEnd   = TNOWMS;

    iBegin = TNOWMS;
    tensorflow::TensorProto keys;
    keys.set_dtype(tensorflow::DataType::DT_INT32);
    for (unsigned int i = 1; i <= sample_size; i++) {
        keys.add_int64_val(i);
    }
    keys.mutable_tensor_shape()->add_dim()->set_size(keys.int64_val_size());
    inputs["keys"] = keys;
    iEnd   = TNOWMS;
    debug_info.tp_keys_time = iEnd - iBegin;


    iBegin = TNOWMS;
    tensorflow::TensorProto indexs;
    indexs.set_dtype(tensorflow::DataType::DT_INT64);
    tensorflow::TensorProto ids; 
    ids.set_dtype(tensorflow::DataType::DT_INT64);
    // long idsArry[] = { 5, 6, 17, 21, 35, 40, 53, 63, 71, 73, 74, 76, 80, 83, 5,
    //     7, 17, 22, 36, 40, 51, 63, 67, 73, 74, 76, 81, 83 };
    unsigned int input_index_size = input_index.size() / 2;
    int row = 0;
    int col = 0;
    for (unsigned int i = 0; i < input_index_size; i++) {
        if (input_index[i * 2] != row) {
            row = input_index[i * 2];
            col = 0;
        }
        // ids.add_int64_val(row);
        ids.add_int64_val(input_index[i * 2 + 1]);
        indexs.add_int64_val(row);
        indexs.add_int64_val(col);
        col++;
    }
    ids.mutable_tensor_shape()->add_dim()->set_size(ids.int64_val_size());
    inputs["ids"] = ids;
    indexs.mutable_tensor_shape()->add_dim()->set_size(indexs.int64_val_size()/2);
    indexs.mutable_tensor_shape()->add_dim()->set_size(2);
    inputs["indexs"] = indexs;
    iEnd   = TNOWMS;
    debug_info.tp_ids_time = iEnd - iBegin;


    iBegin = TNOWMS;
    tensorflow::TensorProto values;
    values.set_dtype(tensorflow::DataType::DT_FLOAT);
    for (unsigned int i = 0; i < input_value.size(); i++) {
        values.add_float_val(input_value[i]);
    }
    values.mutable_tensor_shape()->add_dim()->set_size(values.float_val_size());
    inputs["values"] = values;
    iEnd   = TNOWMS;
    debug_info.tp_values_time = iEnd - iBegin;


    iBegin = TNOWMS;
    tensorflow::TensorProto shape;
    shape.set_dtype(tensorflow::DataType::DT_INT64);
    shape.add_int64_val(sample_size);
    shape.add_int64_val(feature_size);
    shape.mutable_tensor_shape()->add_dim()->set_size(2);
    inputs["shape"] = shape;
    iEnd   = TNOWMS;
    debug_info.tp_shape_time = iEnd - iBegin;


    // TLOGDEBUG("predictRequest="<< predictRequest.DebugString());
    // debug_info.tfrequest_str = predictRequest.DebugString();
}